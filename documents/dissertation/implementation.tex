% Activate the following line by filling in the right side. If for example the name of the root file is Main.tex, write
% "...root = Main.tex" if the chapter file is in the same directory, and "...root = ../Main.tex" if the chapter is in a subdirectory.
 
%!TEX root =  dissertation.tex

\chapter[Design \& Implementation]{Design \& Implementation}

In this chapter, I will discuss HemeWeb's development and implementation. This will consist on how the HemeLB core docker container is developed, how it is deployed, and how the web application is developed.


\section{HemeLB core docker container}

HemeLB core is a docker container that consists of essential software and services needed to run HemeLB simulation. It is the main component that runs the HemeLB simulation on the cloud. Calculations will be done on the container which will be started on the compute nodes of the HemeWeb architecture. 

Previously, there was an effort to make HemeLB software package portable by creating its own container package\footnote{\url{https://github.com/mobernabeu/docker-hemelb}}. It has all the tools needed for HemeLB simulation workflow. Setup tools, post-processing scripts, and a VNC server that allows users to interact with the container's desktop using a browser. It is a step in a right direction towards making HemeLB portable and for peers to replicate and reproduce results of a simulation. However, HemeWeb will not require all those tools installed.

In this phase, I took the previous container and modify the dockerfile, the instructions file to build the container. It is a straightforward process of stripping out the tools not needed by the compute node to run HemeLB simulation. Once all the tools are removed, I modified the base image of the docker container from base ubuntu provided by docker, to base ubuntu provided by phusion. This change of base image allows the container to correctly start SSH service. It is needed to start SSH for the purpose of multi-container HemeLB simulation executions. The original base image has the problem in starting up services and the workaround is more troublesome than just changing the base image. The resulting container is a minimal container that contains only the HemeLB binary and SSH service running.

The modification of the dockerfile of the container is the initial part to make HemeLB core container created correctly. To correctly create the HemeLB container, this dockerfile needs to be integrated into the development workflow of HemeLB. Currently, the modified dockerfile still live under the HemeWeb codebase\footnote{\url{https://github.com/SeiryuZ/HemeWeb/tree/master/hemelb_docker}}. HemeLB development should trigger an automated build of HemeLB core containers with each version of the software it pushes to the public GitHub repositories. In addition, the development team also needs to create a consistent tag naming in order for the HemeLB core containers to be created correctly.


\section{Deployment script}

After creating the HemeLB core container, I proceed to create a deployment script to configure the overall software architecture. It contains many moving parts and configuring the architecture by hand will soon be unmanageable. Deployment script that I created tries to alleviate the pain of deployment by provisioning and configuring the architecture with minimal manual intervention. It is created using a configuration management and orchestration tools called ansible\footnote{\url{https://www.ansible.com}}.

The basic goals of the script are as follow:
\begin{enumerate}
\item Provision the required master instance from cloud vendors
\item Configure the master instance with the correct security and network settings
\item Configure and install all the services needed by HemeWeb
\item Provision required compute instances from cloud vendors
\item Configure the compute instances with the correct security and network settings
\item Configure the compute instances to run HemeLB core docker container
\end{enumerate}

The development of the script is straightforward. I used various modules that are available to ansible, including cloud vendors module, to automate the process as much as possible. The script can provision instances easily, provided with the correct authentication credentials for each cloud vendors. After provisioning, the script will configure the instances until it is ready to be used for running HemeLB in the cloud.

Modularity is one of the concerns when the deployment script was developed. The deployment script should be able to be extended easily. That's why some common functionalities are gathered into its own module that can be called from specific script. These common functionalities are mostly the software installation and configuration part that have no difference between cloud vendors. However, for each specific cloud vendors, the deployment script have different entry path. This deals mainly with the platform-specific way to provision and configures the server instances from the cloud vendors. After this platform-specific deployment script is done, it will then call the common module to configure the instances as required. With this in mind, the deployment script has been developed to be able to be run for three cloud vendors. They are Digital Ocean\footnote{\url{https://www.digitalocean.com}}, Amazon Web Service\footnote{\url{http://aws.amazon.com}}, and Google Cloud Platform\footnote{\url{https://cloud.google.com}}.

The deployment script described in this section is available online at the HemeWeb repository under the deployment folder\footnote{\url{https://github.com/SeiryuZ/HemeWeb/tree/master/deployment }}.




\section{HemeWeb web application}

In this section, I will discuss the bulk of the work of this project which is developing the web application component. The web application component will be the interface for users to interface with HemeLB simulation workflow and is an essential part of this project. It is developed using Python 2.7 and Django web framework\footnote{\url{https://www.djangoproject.com}}. I chose Django web framework due to my previous experience with the web framework and also the existing codebase have tools written in python. Using Django web framework is to make sure that the codebase in HemeLB software package is done mostly consistent with Python. Additionally, using Django also allow me to focus on the development instead of learning the framework due to my past experience with it.



%
%\subsection{Running a simulation}
%
%The main feature of HemeWeb web application is the ability to run HemeLB simulation. Allowing users without technical know how to run the simulation on command line interface to use web browser to run it. The web application take two input files, geometry file and HemeLB configuration file and store it on the master interface. 
%
%The web interface will then allow users to modify the HemeLB configuration file with an in-browser text editor and also configure the job execution like compute instance count, compute instance type, and the HemeLB core container to use. After the configuration is done, the job will be queued into a queue system which are based on a redis Pub/Sub mechanism. 
%
%An asynchronous workers (Different from the web application workers) will then pick up the queued up job. The worker will run an ansible script to startup correct amount of compute unit from the cloud vendor. For this project, amazon web service is the only available cloud vendors. The compute unit will be started up from the state after the configuration on the deployment part, so it will not waste too much time to configure the base image. However, this is not yet ready to run the HemeLB simulation. What the script will do next is to reconfigure the compute unit more, like reconfiguring docker service to point to the correct master address, mounting the remote file system containing the input files, pull the correct HemeLB core container from docker hub, and run the container.
%
%After all the reconfiguration processes are done, the master's asynchronous worker will then fire an mpi job for HemeLB with the correct parameters. HemeLB simulation will run and produce output which will be written to the shared folder with the master instance. The compute instances will be terminated after the simulation is done.
%
%Outputs of the simulations are then made available for the users to be downloaded via the web interface.
%
%These features are part of the original scope of the web application as I planned on my proposal \citep{Steven:2016aa}. However, I extended the web application so that it can handle more cases. The first thing I added were the ability to handle the pre-processing of the input files. The input files that are used by the HemeLB simulation are generated from a geometry generation step that are done before the simulation. This geometry generation step took different input files, a geometry file (.stl) and a profile file (.pr2) to generate the input that HemeLB simulation can parse. 
%
%The way I implement the pre-processing stuff is to add another form for user to add input files to create new job. It receive the .stl and .pr2 file, save them, and queue up an asynchronous job that will pre-process these input into the correct files that will be feed into the HemeLB simulation configuration part.
%
%Also, I added post-processing feature to the web application. The output files generated by the HemeLB simulation are effective to write in parallel. However, these files are not directly viewable by software like VTK viewer. These files need further post-processing, this is where the post-processing step is introduced in HemeWeb. I added the post-processing step, piping the outputted files into two python scripts, into the asynchronous worker. So after the HemeLB simulation step is done, it has an extra responsibility to run the post processing step on the master interface. The outputted files then will be packaged with the original output for download by the user.


\subsection{Architecture}

\subsubsection{Web application components}

\vspace{1cm}

\noindent%
\begin{minipage}{\linewidth}% to keep image and caption on one page
\makebox[\linewidth]{
  \includegraphics[keepaspectratio=true,scale=0.5]{../resources/images/hemeweb_master_components.png}
 }
\captionof{figure}{HemeWeb architecture}\label{fig:hemeweb-components}%      only if needed  
\end{minipage}

\vspace{1cm}

Figure \ref{fig:hemeweb-components} above illustrate how HemeWeb  application process interacts with the other components inside the master instance. It also illustrates how user's HTTP request start a chain of events inside the master master instance that will eventually return a response to the user's browser.

To start, user's browser will send an HTTP request to the master instance. This request will be captured by Nginx process that will act as a reverse proxy.  Nginx\footnote{\url{https://www.nginx.com}} will proxy the HTTP request towards the correct web application server process or serve static files depending on the requested URL. If the request is routed to the web application, HemeWeb web application which is handled by green unicorn\footnote{\url{http://gunicorn.org}} HTTP server will accept the request. This library will run the HemeWeb python code to process the HTTP request by the user. Depending on the type and path of the request, the web application will serve a static HTML as a response, or handle job-related logic that might interact with another part of the system. One of the components the web application might interact with is the PostgreSQL database\footnote{\url{https://www.postgresql.org}}. The database will persist job information locally on the instance to provide persistent information between HTTP request. However, it will be wiped out when the master instance is terminated and is not shared between HemeWeb instances.

Another part of the master instance the HemeWeb application can interact is with the queuing system. HemeWeb can submit a job into the queue which uses Redis datastore\footnote{\url{http://redis.io}} as the queue backend. HemeWeb uses third party library called Django-rq that handles asynchronous background tasks handling using Redis backend. It uses the pub / sub mechanism of Redis to create a lightweight background job workers. HemeWeb process will store the function to be executed, the job instance and parameters to used by the function into the Redis backend. A background worker will look at the queue at an interval and work on a job if there's any in the queue. The worker will execute the function and update the instance with relevant job execution result. Finally, the worker will go back to being idle waiting for next job to be executed.

\subsubsection{Docker components}

\vspace{1cm}

\noindent%
\begin{minipage}{\linewidth}% to keep image and caption on one page
\makebox[\linewidth]{
  \includegraphics[keepaspectratio=true,scale=0.5]{../resources/images/hemeweb_docker.png}
 }
\captionof{figure}{HemeWeb docker component}\label{fig:hemeweb-docker}%      only if needed  
\end{minipage}

\vspace{1cm}

In this section, I will discuss how the docker components interact with its host and each other as illustrated on figure \ref{fig:hemeweb-docker}. In the master instances, job directories are required to be exported via the Networked File System service. These directories need to be exported for the purpose of sharing the folders and files with the compute node. The web application actually do not really interact with the Networked File System, it create or modify the folder, but configuration is handled during deployment process.

Also, in the master instance we have one docker containers running at all time. This container handle the consul service. This service is used by docker service to coordinate inter-host communication. With this service running, docker service running on other hosts will be able to coordinate with the master instance with regards to container network, give its container non-conflicting internal IP. In a nutshell, containers on different hosts can communicate as if they are on a local network. This feature is key in allowing HemeLB simulation to be run inside docker container on multiple host on the cloud platform.

On the other hand, the compute node will first mount the job directory from the master instance. This is done in order to allow HemeLB containers to have shared access on the input and output folders they are going to use. The container will gain access to the folder on the host by using the docker volume mapping features.

Docker containers on the compute node will only run HemeLB core containers. The compute node will pull the appropriate HemeLB core version from docker hub, but if specified version is locally cached on the instance, no network activity will be made. When running the container, the compute unit will coordinate with the consul service on master instance with regards to internal network configuration. Allowing multiple HemeLB core containers on different hosts to communicate with each others. 

After this configuration is done, then the job execution will be done by one of the compute node. It will execute an mpi job for HemeLB with internal IP of all hosts that are started for this particular job.


\subsubsection{Job instance structure}
HemeWeb use django python library to handle the heavy weightlifting with regards to web functionalities. The way job instance is created is also dependent on django's model hierarchy. \textbf{Job} is a class that represent one instance of job simulation. It inherits from django.db.models.Model class that exist within django infrastructure. Django's model class handles the interaction with the database and with the django environment and HemeWeb's job class only need to extend this class to add its own functionality.

HemeWeb's Job class has the following attributes:
\begin{itemize}
    \item id:  This is a unique UUID field that represent the Job ID. UUID field was chosen because it is appropriate for the possibility of sharing the job simulation files between different deployment of HemeWeb. UUID can prevent clashes of ID between these instances.
    \item input\_file, stl\_file, profile\_file, output\_file, configuration\_file:  These attribute keep track of the files that are used by the job. It is stored as path to the file in the local file system, but with django functionalities HemeWeb can work with the file as an object.
    \item container\_image:  This attribute determine which container of HemeLB core will be used in the simulation. Currently, this field is set manually on the code. 
    \item instance\_type: This determines which compute node type will be started for the simulation. 
    \item instance\_count: This attribute determines how many compute node will be started for the simulation. Currently, this is also set manually on the code. 
    \item status: The attribute to determine Job's status, whether it is \textit{queued, added, done, failed, etc}
    \item created: Attribute to keep track when the job is created
    \item updated: Attribute to keep track when the job is updated 
\end{itemize}





\subsubsection{Job instance directory structure}

HemeWeb structure each job's files and configurations into its own folder. I will discuss how it is structure to provide clearer picture on how the application package and work with the job's files.

\begin{lstlisting}
<UPLOAD_FOLDER_DIR>/<JOB_ID>
<UPLOAD_FOLDER_DIR>/<JOB_ID>/inputs/*
<UPLOAD_FOLDER_DIR>/<JOB_ID>/logs/*
<UPLOAD_FOLDER_DIR>/<JOB_ID>/outputs/*
<UPLOAD_FOLDER_DIR>/<JOB_ID>/metadata
\end{lstlisting}

HemeWeb installation can change the upload folder directory as the basis of all job's folder will be located.  Job ID will be generated by the web application using UUID4 scheme, so ID's generated by different instances of HemeWeb should theoretically have really low chance of clashing. This is also why adding previous job to the HemeWeb instance is not problematic, because using auto increment ID will be a problem for multiple installation.

Next, we have the inputs folder inside the job folder. This is where all the inputs and configurations are stored by the web application. There's also logs folder, where the job stdout, stderr, and HemeLB logs are stored. The web application will read from this folder and make it available on the web interface. Outputs folder will be used by the HemeLB simulation to output files on this folder. One final file is the metadata file. This file is used by the web application to store the state of the job. The job is pickled into this metadata file so when it is downloaded, the web application can unpickle the state of the job instance and it is preserved, ready to be used for another simulation.



\subsection{Simulation workflow}

\vspace{1cm}

\noindent%
\begin{minipage}{\linewidth}% to keep image and caption on one page
\makebox[\linewidth]{
  \includegraphics[keepaspectratio=true,scale=0.5]{../resources/images/implementation.png}
 }
\captionof{figure}{HemeWeb flow}\label{fig:hemeweb-implementation}%      only if needed  
\end{minipage}

\vspace{1cm}

Figure \ref{fig:hemeweb-implementation} illustrate how the HemeWeb web application works. it consists of mainly 4 core activity that will be discussed in details in the following section.

\subsubsection{Pre-processing}

HemeWeb handle pre-processing of inputs that are needed so that HemeLB simulation can parse the files. User provide a geometry file (.stl) and a profile file (.pr2) to the web application. HemeWeb will then create a job instance with these two files, save them locally on master instances and queue the pre-processing job.

The asynchronous worker on master instance will then pick up the job whenever they are free. It will run the pre-processing python script to generate the geometry files and HemeLB configuration file. These files will then be saved on the master instance, and HemeWeb will track these files by recording the path to these files on the job instance. Now the job instance is ready for the next step. of the workflow.

\subsubsection{Job configuration}

In this step, HemeWeb application will take a job instance with correctly set geometry file (.gmy) and HemeLB configuration (.xml). However, there are multiple ways that HemeWeb can get this correctly set job instance. As illustrated on Figure \ref{fig:hemeweb-implementation} , there are 4 possible entry points for this step. They are:

\begin{itemize}
    \item \textbf{From the post-processing step.}
    	These files are generated from the previous pre-processing step. The job instance is directly used in this step
    
    \item \textbf{User's provided geometry and configuration file.}
    	User have pre-processed their own file locally, or have their own geometry and configuration files available. HemeWeb will create a new job instance, save both files and keep them tracked with the job instance.
	
    \item \textbf{User's provided previous job ID.}
    	There are two possible case when user specify previous job ID. First, the previous job is available locally on the HemeWeb instance. Second, the previous job is cached on the persistent storage on the cloud vendor and are not available locally. HemeWeb will download the previous file from the persistent storage if it is not available locally. It will then create a new job instance that copy the previous job's geometry file and configuration file to be used for further configuration.
    
    \item \textbf{User's provided simulation file URL.}
    	The last alternative is for user to provide the simulation file URL. Simulation files are uploaded to a persistent storage at the end of the workflow. These files, if made public, can be used by other instance of HemeWeb to download the simulation files and use it as a basis to create a new job instance. The way the system work is the same as using previous job ID, but its source is not its own persistent storage, but other people's simulation files.

\end{itemize}


After the job instance is created from one of the four way possible discussed above, HemeWeb will then ask users for the job configuration. This entails on configuring how many instances should be started, what are the type of the instance, and the hemelb-core container version.  After configuring all these parameters, then the user can queue the job into the queue system.	



\subsubsection{HemeLB simulation}

Once job instance are queued into the simulation queue, free asynchronous workers will pop the queue and run the job. The worker will start up the configured amount and type of server instance from the cloud provider. These instances will then be further reconfigured by an ansible script so that it points to the correct master instance address. Next, input files are shared via Networked File System(NFS), the compute units will mount the input folders to their instance. 

HemeLB core container will be pulled from docker hub in the next step. This step will skip the download if the container asked are already cached in the image for compute unit which are prepared on the deployment part. After all of these are done, then the simulation can finally begin. Master node will issue an mpi command to be run by the leader of compute nodes. The leader of compute node then will run this mpi command in the docker container. This command will be run on multiple compute node if it is configured as such in the previous steps. 

The HemeLB simulation will run until outputs are produced. The output will be written back to the correct output folder in the shared folder. This means that the master instance will have access to the outputs file and can do further processing. This step ends with the termination of the instances.


\subsubsection{Post-processing}

After HemeLB simulation is done, HemeWeb web app will do some post-processing steps to make sure the output files can be viewed easily. The output from HemeLB simulation is structured in such a way that makes it efficient to write in parallel. However, these output cannot be viewed by visualization system like Paraview. What HemeWeb will do is to pipe the output to two scripts that will format the output into a format that can be understood by paraview.


However, the post-processing steps are not done until converting the output. There are further steps that HemeWeb took to make sure that the simulation files, configurations, and results are preserverd. HemeWeb will package the job directory, compressed it, and upload it into persistent storage that cloud vendors provide. As the time of writing, HemeWeb only support amazon S3. The simulation file are uploaded to this storage and made available for public for other HemeWeb instance to use. Also, with the job files persisted on persistent storage. The next HemeWeb instance deployed can take advantage of these files that it can download them as previous job available.







\subsection{Implementation Challenge}


In this section, I will try to outline and discuss the challenges in implementing this project, and if any, the solution that I choose.

\subsubsection{Cloud vendors features and API difference}

The challenge in developing the deployment script is the difference of cloud vendors' API and features.  This has led to some problems when trying to create a common API to do a certain task. One notable problem is that the absence of image creation from running instance feature from one of the cloud vendors. Image creation feature is not an essential requirement of the project. However, with an image creation, the compute nodes that will be requested by the web application can be configured much quicker because all the pre-configuration that are done during the deployment phase. However, one of the cloud vendors does not have this feature. This creates a situation where there is no elegant way to create image with the deployment script and users are asked to manually created the image on the web interface

\vspace{1cm}

\noindent%
\begin{minipage}{\linewidth}% to keep image and caption on one page
\makebox[\linewidth]{
  \includegraphics[keepaspectratio=true,scale=0.4]{../resources/images/hemeweb-challenge-1.png}
 }
\captionof{figure}{Manual image creation instead of automatic}\label{fig:hemeweb-challenge-1}%      only if needed  
\end{minipage}

\vspace{1cm}

Figure \ref{fig:hemeweb-challenge-1} shows how users are instructed to manually create an image from running instance. Users have to go the web interface of specific cloud vendors, right-click on the running instance, and create the image from it. This is a simple workaround which is less complicated compared to accommodating different or missing features and API from different cloud vendors.


Another problem is time constraint. Due to the time constraint, I cannot achieve full compatibility with all cloud vendors. The development time is mainly focused on amazon web service because it has all the features HemeWeb need. However this means that the codebase is currently tied to one cloud vendors. Features like automatically reading past simulation files from cloud storage and uploading simulation files are tied to amazon infrastructure. It is possible to refactor this functionalities out to become more generic, however for the interest of time, I decided not to.

\subsubsection{Security}

Another challenge that I face during the development of HemeWeb is to handle the security of the application. However, security is not the main focus of this work and is apparent in the development of the application. I will still discuss the security issues so that I can give an objective assessment on the application.

The first security issues that I found is with regards to the compute node security in some cloud vendors. Digital ocean for example, does not provide a "real" private networking option within compute nodes. They have a "shared" private networking options that allow other compute nodes, which are not even under your account have network access to your node. Theoretically, this allow other people access to your private compute node if they have the credentials. In this case, I made sure that all the compute nodes have a sensible access policy to deter unauthorized access to the nodes. I only allow ssh with public key and disabled password access to ssh. Also, it is also much better to choose cloud vendors that have real private networking like AWS. In which, the compute nodes are not accessible to other nodes that are not part of your own private network. This is much more secure and sensible.


Another security issue is on how the compute nodes and master node share simulation job's files. It currently use Network File System without any security measures towards the nodes that try to mount it via the private network. There is an opportunity to secure these communication by encrypting the job files, but it is not currently done.


\section{Development process}

The development process is divided into 5 phases. The planned phases are as follow:

\begin{enumerate}
	\item{Separate HemeLB core into its own container}
	\item{Orchestrate the deployment of HemeLB cluster / infrastructure}
	\item{Develop HemeWeb to accept user input}
	\item{Extends HemeWeb to handle geometry generation workflow}
	\item{Extends HemeWeb to handle domain definition step or Viewing of HemeLB simulation result}
\end{enumerate}

The development process loosely follow the agile method in which I regularly meet with the stakeholders every week to give an update and gather feedback on the project. The phase are designed in such a way to minimize the risk of having nothing at all during the end of the project phase. This is due to that HemeWeb can work on its own after finishing step 3. The HemeLB simulation can be done on its own. The rest of the steps are there to extend the functionalities of the HemeWeb to cover more functionalities.

During the first week of the development, I focused more on stripping the HemeLB core container into its own. I researched on how Docker and dockerfile work, and finding out what are the issues with the current container. After identifying the issues, which are ssh service and full of functionalities which are not essential, I stripped down the image and changed the base image so that the container could avoid the mentioned problems. I end up with smaller container size and it is available online on https://hub.docker.com.

However, one particular issue with what i have currently is that the Dockerfile is published as a part of the HemeWeb source code. It should be tied down to the HemeLB development instead of HemeWeb. Currently the development model of HemeLB is that there is an internal private repository where the less than stable build is pushed to it, and there are public repositories where only stable builds are pushed into. The release process should include adding the dockerfile towards the core HemeLB source code repository and tagging the release correctly. HemeLB core containers should then be built automatically on docker hub with regards to additional tags being pushed to the public repository.


After the HemeLB core container, I then focused on how the architecture could be primed for the HemeLB simulation. It involves on configuring the servers and all supporting infrastructures on cloud vendors to be ready for HemeLB simulation. Network configuration, security configuration, docker configuration, and other should be handled automatically. I elect to choose ansible orchestration software because it is closely related to python language that I used. 

In this phase, I successfully achieve the provision and deployment process that with the correct credentials and authorization, the script could provision and configure the architecture correctly so it is ready for HemeLB simulation. In addition to that, I successfully created the script so that it will be cloud vendors agnostic. I can deploy the architecture to google cloud vendors, amazon web service, and digital ocean.

However, it is to be noted that the deployment process that I achieve can only run HemeLB simulation from the command line. I have not considered the web application installation and configuration at this point of the deployment. I am only considering the infrastructure being build and configured for HemeLB simulation.


Next, I started developing HemeWeb web application. I choose django web application framework due to my experience with it. I created a basic interface, where job simulation is listed on the index page on the home interface. After that, I added a basic interface to add new job with a geometry file and hemelb configuration file. The web application will then add those input files into a newly created job instance and configure the job instance in the job configuration step. Job will then be submitted. 

Here I developed a separate ansible script that will be called when a queued job is being worked at. The ansible script is responsible for starting up compute nodes needed by the job and executing HemeLB simulation. After the simulation is done, the script is also responsible for correctly terminating the compute node.

After the basic HemeWeb web application is achieved, I extends it to handle pre-processing. I added an extra form in the adding new job form to handle a profile file and geometry file. These two files will be converted into a geomtery file and HemeLb configuration file that the job configuration steps expect. In addition to adding the interface, I also added a new function on the job instance that will run this pre-processing step on the background. 

Lastly, due to the limited time, I can only manage to run a small post-processing step on HemeWeb. What I did was adding post-processing step that convert the Extracted results from HemeLB output into a format that can be viewed by third party software, ParaView. The results are piped into two scripts that will output a .vtu that is compatible with ParaView. This is done during the background activity after simulation result is outputted. However, currently this is done on the master node.

In addition to that, I also managed to add persistence capability to HemeWeb application. What I did was to package the job simulation folder into a compressed archive and upload it to persistent storage service of cloud vendors. These archives can be queried by another instance of HemeWeb to get previous job IDs available for the particular cloud vendor account used to deploy HemeWeb.  Also, the job simulation file URL is also showed on the web interface. Making it easy for the users to share the simulation file with their peers.




